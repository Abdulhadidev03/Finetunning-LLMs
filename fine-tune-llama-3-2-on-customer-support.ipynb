{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":120005,"sourceType":"modelInstanceVersion","modelInstanceId":100936,"modelId":121027}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:19:43.365504Z","iopub.execute_input":"2025-01-18T08:19:43.365865Z","iopub.status.idle":"2025-01-18T08:20:41.635788Z","shell.execute_reply.started":"2025-01-18T08:19:43.365839Z","shell.execute_reply":"2025-01-18T08:20:41.634913Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format\n","metadata":{"id":"VLzgZ14X_rMs","execution":{"iopub.status.busy":"2025-01-18T08:20:41.637747Z","iopub.execute_input":"2025-01-18T08:20:41.638016Z","iopub.status.idle":"2025-01-18T08:20:41.643857Z","shell.execute_reply.started":"2025-01-18T08:20:41.637990Z","shell.execute_reply":"2025-01-18T08:20:41.643054Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nsecret_value_0 = user_secrets.get_secret(\" HUGGINGFACE_TOKEN\")\nlogin(token = secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:20:41.644925Z","iopub.execute_input":"2025-01-18T08:20:41.645229Z","iopub.status.idle":"2025-01-18T08:20:42.206017Z","shell.execute_reply.started":"2025-01-18T08:20:41.645198Z","shell.execute_reply":"2025-01-18T08:20:42.205115Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"secret_value_1 = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=secret_value_1)\nrun = wandb.init(\n    project='Fine-tune Llama 3.2 on Customer Support Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"id":"na9CAoHC5gM9","execution":{"iopub.status.busy":"2025-01-18T08:20:42.207855Z","iopub.execute_input":"2025-01-18T08:20:42.208114Z","iopub.status.idle":"2025-01-18T08:20:42.366709Z","shell.execute_reply.started":"2025-01-18T08:20:42.208091Z","shell.execute_reply":"2025-01-18T08:20:42.365873Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\nnew_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\ndataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\"","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:20:42.367973Z","iopub.execute_input":"2025-01-18T08:20:42.368695Z","iopub.status.idle":"2025-01-18T08:20:42.373587Z","shell.execute_reply.started":"2025-01-18T08:20:42.368660Z","shell.execute_reply":"2025-01-18T08:20:42.372743Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:20:42.374832Z","iopub.execute_input":"2025-01-18T08:20:42.375344Z","iopub.status.idle":"2025-01-18T08:20:42.392681Z","shell.execute_reply.started":"2025-01-18T08:20:42.375312Z","shell.execute_reply":"2025-01-18T08:20:42.391894Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"id":"StJKGiDDHzdk","outputId":"871214ba-6c30-4ecf-ac68-550f296b7ef6","execution":{"iopub.status.busy":"2025-01-18T08:20:42.393524Z","iopub.execute_input":"2025-01-18T08:20:42.393767Z","iopub.status.idle":"2025-01-18T08:20:50.002084Z","shell.execute_reply.started":"2025-01-18T08:20:42.393746Z","shell.execute_reply":"2025-01-18T08:20:50.000837Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8afdd6d80774c6498a0b28b77056be9"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:20:50.003334Z","iopub.execute_input":"2025-01-18T08:20:50.003622Z","iopub.status.idle":"2025-01-18T08:20:50.009245Z","shell.execute_reply.started":"2025-01-18T08:20:50.003588Z","shell.execute_reply":"2025-01-18T08:20:50.008385Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"modules = find_all_linear_names(model)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:20:50.010411Z","iopub.execute_input":"2025-01-18T08:20:50.010690Z","iopub.status.idle":"2025-01-18T08:20:50.021889Z","shell.execute_reply.started":"2025-01-18T08:20:50.010666Z","shell.execute_reply":"2025-01-18T08:20:50.020993Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"modules","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:20:50.024357Z","iopub.execute_input":"2025-01-18T08:20:50.024630Z","iopub.status.idle":"2025-01-18T08:20:50.035495Z","shell.execute_reply.started":"2025-01-18T08:20:50.024591Z","shell.execute_reply":"2025-01-18T08:20:50.034720Z"},"trusted":true},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['up_proj', 'v_proj', 'q_proj', 'gate_proj', 'down_proj', 'k_proj', 'o_proj']"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\ntokenizer.chat_template = None\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:20:50.036577Z","iopub.execute_input":"2025-01-18T08:20:50.036817Z","iopub.status.idle":"2025-01-18T08:20:57.620576Z","shell.execute_reply.started":"2025-01-18T08:20:50.036796Z","shell.execute_reply":"2025-01-18T08:20:57.619613Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"train\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\ninstruction = \"\"\"You are a top-rated customer service agent named John. \n    Be polite to customers and answer all their questions.\n    \"\"\"\ndef format_chat_template(row):\n    \n    row_json = [{\"role\": \"system\", \"content\": instruction },\n               {\"role\": \"user\", \"content\": row[\"instruction\"]},\n               {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n    \n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)\n\ndataset","metadata":{"id":"XzF2UjPvTBag","outputId":"3733e45f-605e-4564-88c7-368c9c5bf9cd","execution":{"iopub.status.busy":"2025-01-18T08:20:57.621721Z","iopub.execute_input":"2025-01-18T08:20:57.622006Z","iopub.status.idle":"2025-01-18T08:21:02.910853Z","shell.execute_reply.started":"2025-01-18T08:20:57.621980Z","shell.execute_reply":"2025-01-18T08:21:02.910026Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a72a5eb23757412e826540508e4df3b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)t_Training_Dataset_27K_responses-v11.csv:   0%|          | 0.00/19.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5e8456d3e2641dc92e13aecb8fa46fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/26872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cff538071c245e39659a3a18ffd38cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc0a5742b44c45599866ebb503d2e17b"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['flags', 'instruction', 'category', 'intent', 'response', 'text'],\n    num_rows: 1000\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"dataset['text'][3]","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:21:02.912228Z","iopub.execute_input":"2025-01-18T08:21:02.912488Z","iopub.status.idle":"2025-01-18T08:21:02.920800Z","shell.execute_reply.started":"2025-01-18T08:21:02.912462Z","shell.execute_reply":"2025-01-18T08:21:02.919893Z"},"trusted":true},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\"<|im_start|>system\\nYou are a top-rated customer service agent named John. \\n    Be polite to customers and answer all their questions.\\n    <|im_end|>\\n<|im_start|>user\\ncould you tell me about the options for shipping?<|im_end|>\\n<|im_start|>assistant\\nOf course, I'd be delighted to provide you with information about our shipping options! Here are the various choices we offer:\\n\\n1. Standard Shipping: This option typically arrives within {{Date Range}} business days, catering to non-urgent items and ensuring a cost-effective delivery.\\n\\n2. Expedited Shipping: If you're looking for a faster option, choose expedited shipping. Your items will reach you within {{Date Range}} business days, offering a balance between speed and affordability.\\n\\n3. Overnight Shipping: For urgent needs, we have overnight shipping. This ensures your items are delivered on the next business day, offering the highest level of speed and convenience.\\n\\n4. In-Store Pickup: If you prefer a more hands-on approach, you can opt for in-store pickup. This option allows you to collect your items personally from one of our {{Store Location}}, offering added flexibility and convenience.\\n\\nRemember that specific delivery times may vary based on your location and other factors. If you have any further questions or need assistance with any aspect of our shipping options, please feel free to ask. We're here to ensure your satisfaction!<|im_end|>\\n\""},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:21:02.921810Z","iopub.execute_input":"2025-01-18T08:21:02.922039Z","iopub.status.idle":"2025-01-18T08:21:02.941854Z","shell.execute_reply.started":"2025-01-18T08:21:02.922017Z","shell.execute_reply":"2025-01-18T08:21:02.941076Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)\n","metadata":{"id":"peOnLAAhS0y1","execution":{"iopub.status.busy":"2025-01-18T08:21:02.942775Z","iopub.execute_input":"2025-01-18T08:21:02.942970Z","iopub.status.idle":"2025-01-18T08:21:02.983769Z","shell.execute_reply.started":"2025-01-18T08:21:02.942952Z","shell.execute_reply":"2025-01-18T08:21:02.982943Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    processing_class=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:25:16.820985Z","iopub.execute_input":"2025-01-18T08:25:16.821284Z","iopub.status.idle":"2025-01-18T08:25:17.597116Z","shell.execute_reply.started":"2025-01-18T08:25:16.821262Z","shell.execute_reply":"2025-01-18T08:25:17.596448Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e2420fcd874ccf9405b33e738baec5"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"model.config.use_cache = False\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:25:30.070838Z","iopub.execute_input":"2025-01-18T08:25:30.071168Z","iopub.status.idle":"2025-01-18T08:33:27.411564Z","shell.execute_reply.started":"2025-01-18T08:25:30.071139Z","shell.execute_reply":"2025-01-18T08:33:27.410803Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [450/450 07:54, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>90</td>\n      <td>1.778200</td>\n      <td>1.002960</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.659400</td>\n      <td>0.892347</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.861400</td>\n      <td>0.853830</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.234900</td>\n      <td>0.816732</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.894900</td>\n      <td>0.801803</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=450, training_loss=1.8955480670928955, metrics={'train_runtime': 476.7071, 'train_samples_per_second': 1.888, 'train_steps_per_second': 0.944, 'total_flos': 2694027977379840.0, 'train_loss': 1.8955480670928955, 'epoch': 1.0})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()\nmodel.config.use_cache = True","metadata":{"id":"nKgZBEGVS5a2","execution":{"iopub.status.busy":"2025-01-18T08:36:04.621531Z","iopub.execute_input":"2025-01-18T08:36:04.621928Z","iopub.status.idle":"2025-01-18T08:36:06.280851Z","shell.execute_reply.started":"2025-01-18T08:36:04.621900Z","shell.execute_reply":"2025-01-18T08:36:06.280115Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▂▁</td></tr><tr><td>eval/runtime</td><td>▁▇▇▇█</td></tr><tr><td>eval/samples_per_second</td><td>█▂▂▂▁</td></tr><tr><td>eval/steps_per_second</td><td>█▂▂▂▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▆▅▅▆▃▄▃▄▄▅▂▂▂▂▅▃▂▃▂▂▃▅▂▃▂▂▂▂▃▂▃▄▂▁▃▃▄▃▅</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▆▃▃▅▄▃▃▃▂▃▂▁▂▃▂▁▂▂▃▂▂▂▂▃▂▂▂▂▂▁▂▃▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.8018</td></tr><tr><td>eval/runtime</td><td>18.7429</td></tr><tr><td>eval/samples_per_second</td><td>5.335</td></tr><tr><td>eval/steps_per_second</td><td>5.335</td></tr><tr><td>total_flos</td><td>2694027977379840.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>450</td></tr><tr><td>train/grad_norm</td><td>2.7967</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.8949</td></tr><tr><td>train_loss</td><td>1.89555</td></tr><tr><td>train_runtime</td><td>476.7071</td></tr><tr><td>train_samples_per_second</td><td>1.888</td></tr><tr><td>train_steps_per_second</td><td>0.944</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lively-fog-2</strong> at: <a href='https://wandb.ai/abdulhadidev-ned-university-of-engineering-and-technology/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/owp47wmg?apiKey=01248e36b67bd53937dfb8e1ff211d09892a1a5a' target=\"_blank\">https://wandb.ai/abdulhadidev-ned-university-of-engineering-and-technology/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/owp47wmg?apiKey=01248e36b67bd53937dfb8e1ff211d09892a1a5a</a><br> View project at: <a href='https://wandb.ai/abdulhadidev-ned-university-of-engineering-and-technology/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=01248e36b67bd53937dfb8e1ff211d09892a1a5a' target=\"_blank\">https://wandb.ai/abdulhadidev-ned-university-of-engineering-and-technology/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=01248e36b67bd53937dfb8e1ff211d09892a1a5a</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250118_081748-owp47wmg/logs</code>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:36:06.282388Z","iopub.execute_input":"2025-01-18T08:36:06.283128Z","iopub.status.idle":"2025-01-18T08:37:04.211798Z","shell.execute_reply.started":"2025-01-18T08:36:06.283092Z","shell.execute_reply":"2025-01-18T08:37:04.210853Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13430e1dce0a4027b87178b93d664974"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AbdulHadiDev/llama-3.2-3b-it-Ecommerce-ChatBot/commit/3ac23d551d2f73799e851a70a51ce236203afc69', commit_message='Upload model', commit_description='', oid='3ac23d551d2f73799e851a70a51ce236203afc69', pr_url=None, repo_url=RepoUrl('https://huggingface.co/AbdulHadiDev/llama-3.2-3b-it-Ecommerce-ChatBot', endpoint='https://huggingface.co', repo_type='model', repo_id='AbdulHadiDev/llama-3.2-3b-it-Ecommerce-ChatBot'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"messages = [{\"role\": \"system\", \"content\": instruction},\n    {\"role\": \"user\", \"content\": \"I bought the same item twice, cancel order {{Order Number}}\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"execution":{"iopub.status.busy":"2025-01-18T08:37:21.426458Z","iopub.execute_input":"2025-01-18T08:37:21.426730Z","iopub.status.idle":"2025-01-18T08:37:37.890828Z","shell.execute_reply.started":"2025-01-18T08:37:21.426707Z","shell.execute_reply":"2025-01-18T08:37:37.889947Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nI'm sorry to hear that you have purchased the same item twice. I understand your need to cancel the order with the number {{Order Number}}. Let me assist you with that. Please provide me with the necessary details such as the item name, quantity, and any other relevant information, and I'll guide you through the cancellation process. Rest assured, I'm here to help you resolve this situation. How can I assist you further?\n Thank you for bringing this to our attention. I'm here to help you with canceling your order with the number {{Order Number}}. To proceed with the cancellation, could you please provide me with some additional information such as the item name, quantity, and any other relevant details? This will help\n","output_type":"stream"}],"execution_count":36}]}